# app.py
import os
import io
import tempfile
import numpy as np
from PIL import Image
from flask import Flask, request, jsonify, render_template
import cv2
import torch
from transformers import AutoImageProcessor, AutoModelForImageClassification
import torch.nn.functional as F
from statistics import median


MODEL_ID = os.environ.get("HF_MODEL_ID", "Hemg/Deepfake-Detection")
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# load model + processor (same as before)
processor = AutoImageProcessor.from_pretrained(MODEL_ID)
model = AutoModelForImageClassification.from_pretrained(MODEL_ID)
model.to(DEVICE)
model.eval()

# face detector
haar_xml = cv2.data.haarcascades + "haarcascade_frontalface_default.xml"
face_cascade = cv2.CascadeClassifier(haar_xml)

app = Flask(__name__, static_folder="static", template_folder="templates")

def detect_and_crop_face(pil_img):
    np_img = np.array(pil_img.convert("RGB"))
    gray = cv2.cvtColor(np_img, cv2.COLOR_RGB2GRAY)
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=4, minSize=(60,60))
    if len(faces) == 0:
        return pil_img.convert("RGB")
    faces = sorted(faces, key=lambda rect: rect[2]*rect[3], reverse=True)
    x,y,w,h = faces[0]
    pad = int(0.2 * max(w,h))
    x0 = max(0, x-pad); y0 = max(0, y-pad)
    x1 = min(np_img.shape[1], x + w + pad); y1 = min(np_img.shape[0], y + h + pad)
    crop = np_img[y0:y1, x0:x1]
    return Image.fromarray(crop).convert("RGB")
def detect_and_crop_face_strict(pil_img, min_size=64):
    """
    Return cropped PIL image of the largest detected face.
    If no face found, return None.
    """
    arr = np.array(pil_img.convert("RGB"))
    gray = cv2.cvtColor(arr, cv2.COLOR_RGB2GRAY)
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=4, minSize=(min_size, min_size))
    if len(faces) == 0:
        return None
    x, y, w, h = max(faces, key=lambda r: r[2]*r[3])
    pad = int(0.25 * max(w, h))
    x0 = max(0, x - pad); y0 = max(0, y - pad)
    x1 = min(arr.shape[1], x + w + pad); y1 = min(arr.shape[0], y + h + pad)
    crop = arr[y0:y1, x0:x1]
    return Image.fromarray(crop).convert("RGB")

def model_predict_probs(pil_img):
    """Return dict label->score for a single PIL image."""
    inputs = processor(images=pil_img, return_tensors="pt").to(DEVICE)
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        probs = F.softmax(logits, dim=-1).cpu().numpy()[0]
    id2label = getattr(model.config, "id2label", None)
    if id2label is None:
        id2label = {i: f"LABEL_{i}" for i in range(len(probs))}
    return { id2label[i]: float(probs[i]) for i in range(len(probs)) }

def get_fake_score_from_probs(probs_dict):
    """Return a single fake_score in [0,1] using label heuristics."""
    # normalize label keys to lower-case
    lower_map = {k.lower(): v for k, v in probs_dict.items()}
    # common labels: 'fake', 'real'
    if 'fake' in lower_map:
        return lower_map['fake']
    # try variations
    for k in lower_map:
        if 'fake' in k or 'deepfake' in k or 'manipulated' in k:
            return lower_map[k]
    # fallback: if two-class and keys look like '0'/'1' or 'label_0'/...
    if len(lower_map) == 2:
        # assume second label corresponds to 'fake' commonly
        vals = list(lower_map.values())
        # choose the smaller index? We'll return the max as fake-prob if label names unknown:
        # but prefer a heuristic: if any key equals '1' use that
        for k in lower_map:
            if k.strip() == '1':
                return lower_map[k]
        # else assume order arbitrary: take max(prob of labels that contain 'fake' else second value)
        return vals[1]
    # ultimate fallback: return highest probability (not ideal)
    return max(lower_map.values())

@app.route("/")
def index():
    return render_template("index.html")

@app.route("/predict_image", methods=["POST"])
def predict_image_endpoint():
    if "file" not in request.files:
        return jsonify({"error": "no file uploaded"}), 400
    f = request.files["file"]
    try:
        pil = Image.open(io.BytesIO(f.read())).convert("RGB")
    except Exception as e:
        return jsonify({"error": "invalid image", "detail": str(e)}), 400
    # do the same single-image pipeline as before
    crop = detect_and_crop_face(pil)
    probs = model_predict_probs(crop)
    fake_score = get_fake_score_from_probs(probs)
    # build top_results sorted
    top_results = sorted([{"label":k, "score":v} for k,v in probs.items()], key=lambda x: x["score"], reverse=True)
    verdict = "FAKE" if fake_score >= 0.5 else "REAL"
    return jsonify({"verdict": verdict, "fake_score": float(fake_score), "top_results": top_results})

@app.route("/predict_video", methods=["POST"])
def predict_video():
    if "file" not in request.files:
        return jsonify({"error": "no file uploaded"}), 400

    sample_every_n = int(request.form.get("sample_every_n", 15))
    max_samples = int(request.form.get("max_samples", 30))
    # keep threshold for legacy but use combined rules below
    threshold = float(request.form.get("threshold", 0.5))

    vid = request.files["file"]
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
    try:
        vid.save(tmp.name)
        cap = cv2.VideoCapture(tmp.name)
        if not cap.isOpened():
            return jsonify({"error": "could not open video file"}), 400

        frame_index = 0
        sampled = 0
        frame_results = []
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            frame_index += 1
            # sample every N frames
            if frame_index % sample_every_n != 0:
                continue

            # convert frame to PIL
            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            pil = Image.fromarray(rgb)
            # strict face crop; skip frame if no face detected
            crop = detect_and_crop_face_strict(pil, min_size=64)
            if crop is None:
                # no face detected -> skip this frame entirely (do not count toward sampled)
                continue
            # run model on cropped face
            probs = model_predict_probs(crop)
            fake_score = get_fake_score_from_probs(probs)
            frame_results.append({
                "frame_number": frame_index,
                "fake_score": float(fake_score),
                "top_results": sorted([{"label":k,"score":v} for k,v in probs.items()], key=lambda x: x["score"], reverse=True)
            })
            sampled += 1

            if sampled >= max_samples:
                break
        cap.release()
    finally:
        try: os.unlink(tmp.name)
        except: pass

    if len(frame_results) == 0:
        return jsonify({"error": "no frames sampled, try lowering sample_every_n or upload a different video"}), 400

    fake_scores = [fr["fake_score"] for fr in frame_results]
    mean_fake = float(np.mean(fake_scores))
    max_fake = float(np.max(fake_scores))
    med_fake = float(median(fake_scores))
    percent_above = float(sum(1 for s in fake_scores if s >= 0.5) / len(fake_scores))

    # combined rule (recommended)
    is_fake = (mean_fake >= 0.6) or (percent_above >= 0.25) or (max_fake >= 0.95)
    verdict = "FAKE" if is_fake else "REAL"

    return jsonify({
        "verdict": verdict,
        "mean_fake": mean_fake,
        "median_fake": med_fake,
        "max_fake": max_fake,
        "percent_above_0.5": percent_above,
        "sampled_frames": len(frame_results),
        "frames": frame_results
    })

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000, debug=False)
